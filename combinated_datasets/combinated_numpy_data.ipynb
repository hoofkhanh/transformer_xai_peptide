{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b499680-a6fb-4dde-b24c-1c8fd3f5d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:48:12.665516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Concatenate, Reshape, Embedding, GlobalAveragePooling1D, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929031ae-5501-4eb5-b3c3-9ba30e705917",
   "metadata": {},
   "source": [
    "# ĐỌC LẠI FILE NUMPY GENBANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ad5b3b-f33a-427c-b039-4d099904ff27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260000, 126)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_GenBank_loaded = np.load('numpy_GenBank/X_train_num_GenBank.npy')\n",
    "X_train_num_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8a2730-880f-4417-b850-8c13f2f6adf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 126)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_num_GenBank_loaded = np.load('numpy_GenBank/X_val_num_GenBank.npy')\n",
    "X_val_num_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d37228f-df7a-4692-acb0-21d0d6858d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260000, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text_GenBank_loaded = np.load('numpy_GenBank/X_train_text_GenBank.npy')\n",
    "X_train_text_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d836d595-71ce-4017-aefc-b7470c8f483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_text_GenBank_loaded = np.load('numpy_GenBank/X_val_text_GenBank.npy')\n",
    "X_val_text_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62e9ed2-483e-4905-a085-04a9f37d4a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 127)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test_GenBank_loaded = pd.read_csv('numpy_GenBank/X_test_GenBank.csv')\n",
    "# X_test_GenBank_loaded.shape\n",
    "\n",
    "# Đọc dữ liệu theo từng khối nhỏ (100,000 dòng mỗi khối)\n",
    "chunksize = 100000\n",
    "X_test_GenBank_loaded = pd.read_csv('numpy_GenBank/X_test_GenBank.csv', chunksize=chunksize)\n",
    "\n",
    "# Danh sách chứa các khối dữ liệu\n",
    "chunks = []\n",
    "\n",
    "# Duyệt qua từng khối dữ liệu và lưu vào danh sách\n",
    "for chunk in X_test_GenBank_loaded:\n",
    "    # Thêm khối dữ liệu vào danh sách\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Kết hợp tất cả các khối lại thành một DataFrame duy nhất\n",
    "X_test_GenBank_loaded = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Kiểm tra kích thước cuối cùng của DataFrame\n",
    "X_test_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f034b3f8-715d-4b38-8d53-45ab4f7fc255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_GenBank_loaded = np.load('numpy_GenBank/y_train_GenBank.npy')\n",
    "y_train_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce2cdfa-0ee0-4d4d-95a9-1ea6c351b6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_GenBank_loaded = np.load('numpy_GenBank/Y_val_GenBank.npy')\n",
    "Y_val_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4415b0-12b2-4136-a198-8ed5f2c35fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_GenBank_loaded = np.load('numpy_GenBank/Y_test_GenBank.npy')\n",
    "Y_test_GenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db0776-b9a1-442e-9b88-8f329a4cd82b",
   "metadata": {},
   "source": [
    "# ĐỌC NUMPY NOT GENBANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9fa840-cf2f-45cd-9f0c-2e383bb54d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260000, 126)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_notGenBank_loaded = np.load('numpy_notGenBank/X_train_num_notGenBank.npy')\n",
    "X_train_num_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc51a57-e20e-411b-afac-17f1a3fc7056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 126)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_num_notGenBank_loaded = np.load('numpy_notGenBank/X_val_num_notGenBank.npy')\n",
    "X_val_num_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab25804-707a-4e97-9c31-03d7187490e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260000, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text_notGenBank_loaded = np.load('numpy_notGenBank/X_train_text_notGenBank.npy')\n",
    "X_train_text_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e7463b-d630-4e32-afb2-f1fdebb0e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_text_notGenBank_loaded = np.load('numpy_notGenBank/X_val_text_notGenBank.npy')\n",
    "X_val_text_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c839799-2060-473c-975c-3f9710c54c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 127)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test_notGenBank_loaded = pd.read_csv('numpy_notGenBank/X_test_notGenBank.csv')\n",
    "# X_test_notGenBank_loaded.shape\n",
    "\n",
    "# Đọc dữ liệu theo từng khối nhỏ (100,000 dòng mỗi khối)\n",
    "chunksize = 100000\n",
    "X_test_notGenBank_loaded = pd.read_csv('numpy_notGenBank/X_test_notGenBank.csv', chunksize=chunksize)\n",
    "\n",
    "# Danh sách chứa các khối dữ liệu\n",
    "chunks = []\n",
    "\n",
    "# Duyệt qua từng khối dữ liệu và lưu vào danh sách\n",
    "for chunk in X_test_notGenBank_loaded:\n",
    "    # Thêm khối dữ liệu vào danh sách\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Kết hợp tất cả các khối lại thành một DataFrame duy nhất\n",
    "X_test_notGenBank_loaded = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Kiểm tra kích thước cuối cùng của DataFrame\n",
    "X_test_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6733201-54da-4943-855c-395bc2d8c4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_notGenBank_loaded = np.load('numpy_notGenBank/y_train_notGenBank.npy')\n",
    "y_train_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac8d1c71-cd27-473c-a775-f215bb1ed88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_notGenBank_loaded = np.load('numpy_notGenBank/Y_val_notGenBank.npy')\n",
    "Y_val_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f66ced18-367a-413f-b076-635bbcd1ca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_notGenBank_loaded = np.load('numpy_notGenBank/Y_test_notGenBank.npy')\n",
    "Y_test_notGenBank_loaded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26cf01-a02b-4297-83fa-b59af767a276",
   "metadata": {},
   "source": [
    "# CONCAT DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb78d9e8-795e-431a-b664-38dfe9886cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = np.concatenate([X_train_num_GenBank_loaded, X_train_num_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf0c0c0-1a62-46f3-a211-6d300c2b77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_num = np.concatenate([X_val_num_GenBank_loaded, X_val_num_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f81f4f55-cde6-4bea-b27e-b215d1267b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = np.concatenate([X_train_text_GenBank_loaded, X_train_text_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a088ec9e-040a-4ee7-b356-1bc5a942d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_text = np.concatenate([X_val_text_GenBank_loaded, X_val_text_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcf328b3-d4a9-4736-8977-7aa36376c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test_GenBank_loaded, X_test_notGenBank_loaded], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a61070-18f5-4fd4-bfe0-806457495d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([y_train_GenBank_loaded, y_train_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a592966-ea19-4a61-ac15-717b1976fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val = np.concatenate([Y_val_GenBank_loaded, Y_val_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a32600-193b-4062-8ac2-1ec7eebe477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.concatenate([Y_test_GenBank_loaded, Y_test_notGenBank_loaded], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47117ff-0e1e-4388-9492-93430ef92d74",
   "metadata": {},
   "source": [
    "# CHECK SAU CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e03e0ef3-6a70-4368-9310-609bed85dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520000, 126)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bac6773-9ef3-490e-920b-cf4d4ad830f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000, 126)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfcbe7f5-69ba-4731-83b5-3bb4191b5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520000, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbc7e0db-4853-439f-9714-553c9c7118b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "113197c1-0068-4b68-bc14-77962408877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000, 127)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b91769c7-f690-4591-82a9-e251b2cb5343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcf51c95-388f-4adf-9bac-e9eca2620da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c06d8c0-1449-46d3-8f87-af0cf8875f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ae023-d49d-47c6-a314-f9df5157e2dc",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25470e88-8754-4ca6-978a-1a57c21b3cfe",
   "metadata": {},
   "source": [
    "### Các class huấn luyện model\n",
    "#### - Điều kiện quan trọng: embed_dim phải chia hết cho heads để mỗi đầu Attention có kích thước vector bằng nhau.\n",
    "#### - Thông thường, số neurons trong FFN (neurons) nên gấp 2-4 lần embed_dim để mô hình có đủ khả năng trích xuất đặc trưng.\n",
    "#### - Gợi ý công thức: neurons = 2 × embed_dim hoặc neurons = 4 × embed_dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7541044-b2cd-45d9-8b8d-b43410a11991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa Transformer Encoder\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, heads, neurons):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=heads, key_dim=embed_dim // heads) # NOTE\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(neurons, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(0.2)\n",
    "        self.dropout2 = layers.Dropout(0.2)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        if mask is not None:\n",
    "            # MHA yêu cầu mask shape: (batch_size, 1, 1, seq_len) hoặc (batch_size, seq_len)\n",
    "            mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32)  # (batch_size, 1, seq_len)\n",
    "    \n",
    "        attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Lớp embedding cho chuỗi văn bản\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        positions = tf.range(start=0, limit=self.maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x_embed = self.token_emb(x)\n",
    "        return x_embed + positions, self.token_emb.compute_mask(x)\n",
    "\n",
    "\n",
    "class MultiLayerTransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_layers, embed_dim, heads, neurons):\n",
    "        super(MultiLayerTransformerEncoder, self).__init__()\n",
    "        self.encoders = [\n",
    "            TransformerEncoder(embed_dim, heads, neurons)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, x, mask=None, training=False):\n",
    "        for encoder_layer in self.encoders:\n",
    "            x = encoder_layer(x, training=training, mask=mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a90fc46-80e4-47aa-8412-cb1c7b2ccc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:50:34.589751: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-05-05 17:50:34.676605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-05-05 17:50:34.857718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:34.863863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.58GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2025-05-05 17:50:34.864953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-05 17:50:34.949938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-05 17:50:34.950064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-05-05 17:50:34.998312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-05 17:50:35.009474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-05 17:50:35.098877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-05-05 17:50:35.110566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-05-05 17:50:35.256782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-05-05 17:50:35.257058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:35.260201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:35.264589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-05-05 17:50:35.269389: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-05 17:50:35.269840: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-05-05 17:50:35.271070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:35.273815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.58GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2025-05-05 17:50:35.273875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-05 17:50:35.273907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-05 17:50:35.273924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-05-05 17:50:35.273940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-05 17:50:35.273955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-05 17:50:35.273970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-05-05 17:50:35.274004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-05-05 17:50:35.274023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-05-05 17:50:35.274103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:35.276815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:35.279337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-05-05 17:50:35.280815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-05 17:50:37.344908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-05-05 17:50:37.344939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2025-05-05 17:50:37.346008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2025-05-05 17:50:37.347426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:37.349391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:37.351076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-05-05 17:50:37.352649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13806 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TransformerEncoder.call of <__main__.TransformerEncoder object at 0x776783545f10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TransformerEncoder.call of <__main__.TransformerEncoder object at 0x776783545f10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# ==== THAM SỐ ====\n",
    "# Đảm bảo TensorFlow đang chạy trong Eager Execution\n",
    "\n",
    "embed_dim = 200   # Kích thước vector embedding\n",
    "heads = 6        # Số đầu attention\n",
    "neurons = 400     # Số nơ-ron của lớp fully connected\n",
    "maxlen = 50      # Chiều dài chuỗi đầu vào (thay max_length bằng 100)\n",
    "num_features = 126  # Số lượng cột số đầu vào\n",
    "vocab_size = 26   # Kích thước từ vựng\n",
    "num_layers = 6    # Số lớp transformer encoder\n",
    "\n",
    "# ==== ĐỊNH NGHĨA INPUT ====\n",
    "# Input cho dữ liệu số\n",
    "num_input = Input(shape=(num_features,))\n",
    "num_reshaped = Dense(embed_dim, activation=\"relu\")(num_input)\n",
    "num_reshaped = Reshape((1, embed_dim))(num_reshaped)  # Shape: (batch_size, 1, embed_dim)\n",
    "\n",
    "# Input văn bản\n",
    "text_input = Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "text_embedded, text_mask = embedding_layer(text_input)  # Shape: (batch_size, maxlen, embed_dim), (batch_size, maxlen)\n",
    "\n",
    "# Ghép 2 đầu vào: (1 + maxlen, embed_dim)\n",
    "merged_input = Concatenate(axis=1)([num_reshaped, text_embedded])\n",
    "\n",
    "# Ghép mask: num_input không phải padding → mask = 1\n",
    "def create_combined_mask(text_mask):\n",
    "    # Tạo mask cho dữ liệu số (num_input) với giá trị là 1\n",
    "    num_mask = tf.ones_like(text_mask[:, :1], dtype=tf.int32)  # num_mask sẽ có kiểu int32\n",
    "    text_mask = tf.cast(text_mask, dtype=tf.int32)  # Chuyển text_mask sang kiểu int32\n",
    "    return tf.concat([num_mask, text_mask], axis=1)\n",
    "\n",
    "\n",
    "merged_mask = Lambda(\n",
    "    create_combined_mask,\n",
    "    output_shape=(maxlen + 1,)\n",
    ")(text_mask)\n",
    "\n",
    "# Nếu cần, reshape thêm cho phù hợp với attention mask yêu cầu\n",
    "merged_mask = Lambda(lambda x: tf.cast(tf.expand_dims(x, axis=1), tf.float32))(merged_mask)\n",
    "\n",
    "# Transformer encoder\n",
    "multi_encoder = MultiLayerTransformerEncoder(num_layers=num_layers, embed_dim=embed_dim, heads=heads, neurons=neurons)\n",
    "x = multi_encoder(merged_input, mask=merged_mask)\n",
    "\n",
    "# Global Average Pooling để giảm chiều dữ liệu\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Fully connected layers\n",
    "x = Dense(neurons, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(embed_dim, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output (ví dụ: classification với softmax, có thể thay đổi)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ef29b1a-1439-474f-adfa-42121d7964f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 126)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          25400       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "token_and_position_embedding (T ((None, 50, 200), (N 15200       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 200)       0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 51)           0           token_and_position_embedding[0][1\n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 51, 200)      0           reshape[0][0]                    \n",
      "                                                                 token_and_position_embedding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 51)        0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_layer_transformer_encoder (None, 51, 200)      1923564     concatenate[0][0]                \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 200)          0           multi_layer_transformer_encoder[0\n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 400)          80400       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 400)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 200)          80200       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 200)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            201         dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,124,965\n",
      "Trainable params: 2,124,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ==== TẠO MÔ HÌNH ====\n",
    "model = Model(inputs=[num_input, text_input], outputs=output)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.000000005)  # Giảm tốc độ học thêm\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Hiển thị mô hình\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f8859e7-0dc5-4ae3-9db3-61552088538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('combinated_datasets_weights.best.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017403d5-854c-4038-a2ea-a2e2162ecc80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Đang chạy sập máy - nên mất history accuracy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "948c51e2-b72d-4083-b38d-953299404854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 08:27:56.702494: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-05-04 08:27:56.711413: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 08:27:59.920035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78750/78750 [==============================] - 1606s 20ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01948, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 2/400\n",
      "78750/78750 [==============================] - 1606s 20ms/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 0.0194 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01948 to 0.01939, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 3/400\n",
      "78750/78750 [==============================] - 1603s 20ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.0193 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01939 to 0.01931, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 4/400\n",
      "78750/78750 [==============================] - 1621s 21ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01931 to 0.01923, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 5/400\n",
      "78750/78750 [==============================] - 1622s 21ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01923 to 0.01916, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 6/400\n",
      "78750/78750 [==============================] - 1623s 21ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.0191 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01916 to 0.01908, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 7/400\n",
      "78750/78750 [==============================] - 1624s 21ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.0190 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01908 to 0.01900, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 8/400\n",
      "78750/78750 [==============================] - 1628s 21ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0189 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01900 to 0.01893, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 9/400\n",
      "78750/78750 [==============================] - 1636s 21ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 0.0189 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01893 to 0.01886, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 10/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0188 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01886 to 0.01878, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 11/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.0187 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01878 to 0.01871, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 12/400\n",
      "78750/78750 [==============================] - 1630s 21ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 0.0186 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01871 to 0.01864, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 13/400\n",
      "78750/78750 [==============================] - 1633s 21ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.0186 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01864 to 0.01857, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 14/400\n",
      "78750/78750 [==============================] - 1637s 21ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 0.0185 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01857 to 0.01851, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 15/400\n",
      "78750/78750 [==============================] - 1629s 21ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.0184 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01851 to 0.01844, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 16/400\n",
      "78750/78750 [==============================] - 1624s 21ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0184 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01844 to 0.01838, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 17/400\n",
      "78750/78750 [==============================] - 1624s 21ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 0.0183 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01838 to 0.01831, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 18/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.0182 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01831 to 0.01824, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 19/400\n",
      "78750/78750 [==============================] - 1623s 21ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0182 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01824 to 0.01819, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 20/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0181 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01819 to 0.01813, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 21/400\n",
      "78750/78750 [==============================] - 1625s 21ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0181 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01813 to 0.01806, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 22/400\n",
      "78750/78750 [==============================] - 1630s 21ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0180 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01806 to 0.01800, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 23/400\n",
      "78750/78750 [==============================] - 1628s 21ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.0179 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01800 to 0.01795, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 24/400\n",
      "78750/78750 [==============================] - 1624s 21ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0179 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01795 to 0.01789, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 25/400\n",
      "78750/78750 [==============================] - 1623s 21ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.0178 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01789 to 0.01783, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 26/400\n",
      "78750/78750 [==============================] - 1628s 21ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.0178 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01783 to 0.01778, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 27/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.0177 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01778 to 0.01773, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 28/400\n",
      "78750/78750 [==============================] - 1628s 21ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0177 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01773 to 0.01767, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 29/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0176 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01767 to 0.01762, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 30/400\n",
      "78750/78750 [==============================] - 1625s 21ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0176 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01762 to 0.01756, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 31/400\n",
      "78750/78750 [==============================] - 1627s 21ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.0175 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01756 to 0.01752, saving model to combinated_datasets_weights.best.weights.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999969612646e-10.\n",
      "Epoch 32/400\n",
      "78750/78750 [==============================] - 1625s 21ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.0175 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01752 to 0.01752, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 33/400\n",
      "29185/78750 [==========>...................] - ETA: 15:56 - loss: 0.0175 - accuracy: 0.9955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Đầu vào gồm dữ liệu số và dữ liệu chuỗi\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation cũng có hai đầu vào\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Dùng danh sách callbacks đã khai báo ở cell 1\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_num, X_train_text], y_train,  # Đầu vào gồm dữ liệu số và dữ liệu chuỗi\n",
    "    validation_data=([X_val_num, X_val_text], Y_val),  # Validation cũng có hai đầu vào\n",
    "    epochs=400,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks_list  # Dùng danh sách callbacks đã khai báo ở cell 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86429037-8f79-4a55-b678-bb485e52dc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:37:38.500837: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-05-03 14:37:38.501313: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:37:41.935234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78750/78750 [==============================] - 1622s 21ms/step - loss: 0.6943 - accuracy: 0.5364 - val_loss: 0.6180 - val_accuracy: 0.6897\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61802, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 2/400\n",
      "78750/78750 [==============================] - 1619s 21ms/step - loss: 0.6338 - accuracy: 0.6644 - val_loss: 0.5463 - val_accuracy: 0.7335\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61802 to 0.54633, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 3/400\n",
      "78750/78750 [==============================] - 1620s 21ms/step - loss: 0.5699 - accuracy: 0.7580 - val_loss: 0.4612 - val_accuracy: 0.7811\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54633 to 0.46122, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 4/400\n",
      "78750/78750 [==============================] - 1623s 21ms/step - loss: 0.4885 - accuracy: 0.8306 - val_loss: 0.3572 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46122 to 0.35717, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 5/400\n",
      "78750/78750 [==============================] - 1630s 21ms/step - loss: 0.3898 - accuracy: 0.8883 - val_loss: 0.2448 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35717 to 0.24479, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 6/400\n",
      "78750/78750 [==============================] - 1634s 21ms/step - loss: 0.2804 - accuracy: 0.9324 - val_loss: 0.1475 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.24479 to 0.14751, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 7/400\n",
      "78750/78750 [==============================] - 1633s 21ms/step - loss: 0.1830 - accuracy: 0.9634 - val_loss: 0.0798 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14751 to 0.07982, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 8/400\n",
      "78750/78750 [==============================] - 1633s 21ms/step - loss: 0.1104 - accuracy: 0.9823 - val_loss: 0.0444 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.07982 to 0.04444, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 9/400\n",
      "78750/78750 [==============================] - 1635s 21ms/step - loss: 0.0666 - accuracy: 0.9904 - val_loss: 0.0298 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04444 to 0.02976, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 10/400\n",
      "78750/78750 [==============================] - 1635s 21ms/step - loss: 0.0449 - accuracy: 0.9929 - val_loss: 0.0246 - val_accuracy: 0.9943\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02976 to 0.02456, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 11/400\n",
      "78750/78750 [==============================] - 1633s 21ms/step - loss: 0.0346 - accuracy: 0.9938 - val_loss: 0.0226 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02456 to 0.02263, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 12/400\n",
      "78750/78750 [==============================] - 1626s 21ms/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0219 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02263 to 0.02188, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 13/400\n",
      "78750/78750 [==============================] - 1637s 21ms/step - loss: 0.0269 - accuracy: 0.9944 - val_loss: 0.0216 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02188 to 0.02156, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 14/400\n",
      "78750/78750 [==============================] - 1634s 21ms/step - loss: 0.0254 - accuracy: 0.9945 - val_loss: 0.0214 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02156 to 0.02140, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 15/400\n",
      "78750/78750 [==============================] - 1634s 21ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.0213 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02140 to 0.02131, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 16/400\n",
      "78750/78750 [==============================] - 1633s 21ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0212 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02131 to 0.02125, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 17/400\n",
      "78750/78750 [==============================] - 1622s 21ms/step - loss: 0.0229 - accuracy: 0.9948 - val_loss: 0.0212 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02125 to 0.02119, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 18/400\n",
      "78750/78750 [==============================] - 1617s 21ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.0211 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02119 to 0.02114, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 19/400\n",
      "78750/78750 [==============================] - 1613s 20ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0211 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02114 to 0.02108, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 20/400\n",
      "78750/78750 [==============================] - 1614s 20ms/step - loss: 0.0223 - accuracy: 0.9948 - val_loss: 0.0210 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02108 to 0.02102, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 21/400\n",
      "78750/78750 [==============================] - 1609s 20ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0209 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02102 to 0.02095, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 22/400\n",
      "78750/78750 [==============================] - 1609s 20ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.0209 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02095 to 0.02087, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 23/400\n",
      "78750/78750 [==============================] - 1607s 20ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 0.0208 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02087 to 0.02080, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 24/400\n",
      "78750/78750 [==============================] - 1607s 20ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.0207 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02080 to 0.02071, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 25/400\n",
      "78750/78750 [==============================] - 1605s 20ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0206 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.02071 to 0.02063, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 26/400\n",
      "78750/78750 [==============================] - 1606s 20ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0205 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.02063 to 0.02054, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 27/400\n",
      "78750/78750 [==============================] - 1605s 20ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.0205 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.02054 to 0.02045, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 28/400\n",
      "78750/78750 [==============================] - 1608s 20ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0204 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.02045 to 0.02036, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 29/400\n",
      "78750/78750 [==============================] - 1608s 20ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0203 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.02036 to 0.02027, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 30/400\n",
      "78750/78750 [==============================] - 1608s 20ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0202 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.02027 to 0.02018, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 31/400\n",
      "78750/78750 [==============================] - 1600s 20ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.0201 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.02018 to 0.02009, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 32/400\n",
      "78750/78750 [==============================] - 1592s 20ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.0200 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.02009 to 0.02000, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 33/400\n",
      "78750/78750 [==============================] - 1583s 20ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.0199 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.02000 to 0.01991, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 34/400\n",
      "78750/78750 [==============================] - 1581s 20ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.0198 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01991 to 0.01982, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 35/400\n",
      "78750/78750 [==============================] - 1574s 20ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0197 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01982 to 0.01973, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 36/400\n",
      "78750/78750 [==============================] - 1577s 20ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0196 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01973 to 0.01964, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 37/400\n",
      "78750/78750 [==============================] - 1578s 20ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0196 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01964 to 0.01956, saving model to combinated_datasets_weights.best.weights.h5\n",
      "Epoch 38/400\n",
      "  514/78750 [..............................] - ETA: 24:21 - loss: 0.0156 - accuracy: 0.9964"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_num, X_train_text], y_train,  # Đầu vào gồm dữ liệu số và dữ liệu chuỗi\n",
    "    validation_data=([X_val_num, X_val_text], Y_val),  # Validation cũng có hai đầu vào\n",
    "    epochs=400,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks_list  # Dùng danh sách callbacks đã khai báo ở cell 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196332f-aef0-43ea-ae4f-9d1ee2e59124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_accuracy(history):\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_history_accuracy(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f59810-c866-4025-a0d8-0e394b1fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(history):\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_history_loss(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfedc4-d50a-4d39-b97e-713029e46a6e",
   "metadata": {},
   "source": [
    "### Ma trận nhầm lẫn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "258ee640-fcb1-47a2-a151-e5cbc846d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = X_test.iloc[:, :126]  # Chọn 126 cột đầu tiên\n",
    "X_test_text = X_test.iloc[:, -1]   # Chọn cột cuối cùng\n",
    "\n",
    "# X_test_num = np.array(X_test_num, dtype=np.float32)\n",
    "X_test_num = X_test_num.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fc52b77-7c29-4562-90e7-89632f3813fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # abstract syntax tree\n",
    "\n",
    "X_test_text = [ast.literal_eval(seq) if isinstance(seq, str) else seq for seq in X_test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75d3e688-eaf4-4b99-9654-1356f3058441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_text shape: (540000, 50)\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "X_test_text = np.array([\n",
    "    seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len]\n",
    "    for seq in X_test_text\n",
    "], dtype=np.int32)\n",
    "\n",
    "print(\"X_train_text shape:\", X_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ee7716b-9e46-403a-8596-3117545c3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:51:39.459818: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-05-05 17:51:39.476366: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n",
      "2025-05-05 17:51:40.052023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16875/16875 [==============================] - 99s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([X_test_num, X_test_text],verbose = True)\n",
    "predictions = (predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09b67685-d2e3-4863-bb78-0d6021d4e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "nAMP (Class 0)       1.00      0.99      1.00    270000\n",
      " AMP (Class 1)       0.99      1.00      1.00    270000\n",
      "\n",
      "      accuracy                           1.00    540000\n",
      "     macro avg       1.00      1.00      1.00    540000\n",
      "  weighted avg       1.00      1.00      1.00    540000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(Y_test, predictions, target_names=['nAMP (Class 0)', 'AMP (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfe162e9-cfb7-4ba7-b2b5-ef1042b65a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, predictions)\n",
    "cm = pd.DataFrame(cm, index=['nAMP', 'AMP'], columns=['nAMP', 'AMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d38a531-e88f-45c6-b705-324017db759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, cmap=\"Blues\", linecolor='black', linewidth=1, annot=True, fmt='d', xticklabels=cm.columns, yticklabels=cm.index)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2c6c8-95a9-4c77-9ee6-034bcdf4c01b",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56206986-1784-4201-84eb-19034066efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = X_test.iloc[:, :126]  # Chọn 126 cột đầu tiên\n",
    "X_test_text = X_test.iloc[:, -1]   # Chọn cột cuối cùng\n",
    "\n",
    "X_test_num = X_test_num.to_numpy(dtype=np.float32)\n",
    "\n",
    "# Định nghĩa độ dài cố định cho X_train_text và X_val_text\n",
    "max_len = 50  \n",
    "\n",
    "# Chuyển đổi tất cả thành danh sách cùng kích thước\n",
    "X_test_text = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in X_test_text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b5c55-30f6-4843-adc4-3367e64725eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train_num.shape[1]\n",
    "text_features = X_train_text.shape[1]\n",
    "\n",
    "def predict_proba_lime(X):\n",
    "    X_num = X[:, 0:num_features]\n",
    "    X_text = X[:, num_features:(num_features + text_features)] \n",
    " \n",
    "    # Dự đoán từ mô hình\n",
    "    probs = model.predict([X_num, X_text])  \n",
    "    \n",
    "    # print(f\"Trước khi flatten {probs.shape}\")\n",
    "    probs = probs.flatten()  # Chuyển thành mảng một chiều\n",
    "    print(f\"Sau khi flatten {probs.shape}\")\n",
    "\n",
    "    # Xác suất cho class 0 và class 1\n",
    "    probs_class_0 = 1 - probs  \n",
    "    probs_class_1 = probs   \n",
    "    # print(f\"probs_class_0 {probs_class_0.shape}\")\n",
    "    # print(f\"probs_class_1 {probs_class_1.shape}\")\n",
    "\n",
    "    result = np.hstack([probs_class_0[:, np.newaxis], probs_class_1[:, np.newaxis]])\n",
    "    # print(result)\n",
    "    # print(f\"result {result.shape}\")\n",
    "    \n",
    "    # Trả về mảng 2 chiều với xác suất của cả hai lớp\n",
    "    return result# class 0, class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a2554-ba15-4bb5-b359-4038792322be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import lime\n",
    "\n",
    "class_names = ['nAMP', 'AMP']\n",
    "\n",
    "feature_names = data_amp.drop(columns=['ID', 'Label', 'Sequence']).columns.tolist()\n",
    "text_feature_names = [f\"text_feat_{i}\" for i in range(X_train_text.shape[1])]\n",
    "full_feature_names = feature_names + text_feature_names\n",
    "\n",
    "X_train_combined = np.concatenate([X_train_num, X_train_text], axis=1)\n",
    "    \n",
    "explainer = LimeTabularExplainer(X_train_combined, feature_names =     \n",
    "                                 full_feature_names,\n",
    "                                 class_names = class_names, \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8079d02-dd1a-415f-8781-f560f3964e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = X_test_num[12]\n",
    "sample_text = X_test_text[12]\n",
    "sample = np.concatenate([sample_num, sample_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e604692-1e04-4fdb-beac-b1f9b5e536c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    data_row=sample, \n",
    "    predict_fn=predict_proba_lime\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)\n",
    "# exp.save_to_file('lime_explanation1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a5f99-3b48-4677-8a6b-a09429b021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Khởi tạo 4 mảng\n",
    "amp_num = []\n",
    "amp = []\n",
    "namp_num = []\n",
    "namp = []\n",
    "\n",
    "# Hiển thị kết quả giải thích LIME\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=sample, \n",
    "    predict_fn=predict_proba_lime\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)\n",
    "\n",
    "# Lấy danh sách các đặc trưng quan trọng\n",
    "important_features = exp.as_list()\n",
    "\n",
    "# Duyệt qua từng đặc trưng\n",
    "for feature, weight in important_features:\n",
    "    match = re.search(r'(num|text)_feat_(\\d+)', feature)\n",
    "    if match:\n",
    "        kind = match.group(1)       # 'num' hoặc 'text'\n",
    "        index = int(match.group(2)) # số đặc trưng\n",
    "\n",
    "        if weight > 0:  # Class AMP (1)\n",
    "            if kind == 'num':\n",
    "                amp_num.append(index)\n",
    "            else:\n",
    "                amp.append(index)\n",
    "        else:           # Class NAMP (0)\n",
    "            if kind == 'num':\n",
    "                namp_num.append(index)\n",
    "            else:\n",
    "                namp.append(index)\n",
    "\n",
    "# In kết quả\n",
    "print(\"AMP - num:\", amp_num)\n",
    "print(\"AMP - text:\", amp)\n",
    "print(\"NAMP - num:\", namp_num)\n",
    "print(\"NAMP - text:\", namp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c2d8f-a79c-42c2-8b9c-6f404a68f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy độ dài tối đa của sample_text\n",
    "last_50 = sample[-50:]\n",
    "\n",
    "text_len = len(sample_text)\n",
    "\n",
    "# Lấy các từ từ tokenizer\n",
    "id2word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "# Lọc và lấy từ cho amp (chỉ số thuộc class 1), đồng thời sắp xếp theo thứ tự của sample_text\n",
    "amp_text_words = [(i, id2word.get(sample_text[i], \"<UNK>\")) for i in amp if i < text_len and sample_text[i] != 0]\n",
    "amp_text_words.sort(key=lambda x: x[0])  # Sắp xếp theo chỉ số\n",
    "\n",
    "# Lọc và lấy từ cho namp (chỉ số thuộc class 0), đồng thời sắp xếp theo thứ tự của sample_text\n",
    "namp_text_words = [(i, id2word.get(sample_text[i], \"<UNK>\")) for i in namp if i < text_len and sample_text[i] != 0]\n",
    "namp_text_words.sort(key=lambda x: x[0])  # Sắp xếp theo chỉ số\n",
    "\n",
    "# Lấy từ đã sắp xếp\n",
    "amp_text_words_sorted = [word for _, word in amp_text_words]\n",
    "namp_text_words_sorted = [word for _, word in namp_text_words]\n",
    "\n",
    "# Tokenize lại các từ đã lấy ra\n",
    "amp_text_tokens = tokenizer.texts_to_sequences([amp_text_words_sorted])[0]\n",
    "namp_text_tokens = tokenizer.texts_to_sequences([namp_text_words_sorted])[0]\n",
    "\n",
    "# In kết quả\n",
    "print('Peptide text: ', \" \".join([id2word.get(i, \"<UNK>\") for i in sample_text if i != 0]))\n",
    "print(\"AMP (class 1) words:\", amp_text_words_sorted)\n",
    "print(\"AMP (class 1) tokens:\", amp_text_tokens)\n",
    "print(\"NAMP (class 0) words:\", namp_text_words_sorted)\n",
    "print(\"NAMP (class 0) tokens:\", namp_text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469dca79-de0d-4d05-b35d-20c52dab6d4b",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500dd35b-82c1-4803-8557-9352436d5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa97d9-42e9-4072-b75b-b1265776d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách đặc trưng số và văn bản từ tập test\n",
    "X_test_num = X_test.iloc[:, :126]  # 126 đặc trưng số\n",
    "X_test_text = X_test.iloc[:, -1]   # 1 cột văn bản nhưng được padding lên 1558 chiều\n",
    "\n",
    "# Chuyển đổi thành mảng numpy\n",
    "# X_test_num = np.array(X_test_num, dtype=np.float32)\n",
    "X_test_num = X_test_num.to_numpy(dtype=np.float32)\n",
    "\n",
    "# Định nghĩa độ dài cố định cho dữ liệu text (1558 chiều)\n",
    "max_len = 50  \n",
    "X_test_text = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in X_test_text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92a831-1060-49a8-9aca-1e73db38ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tổng số đặc trưng: 126 số + 1558 text = 1684\n",
    "num_features = X_test_num.shape[1]\n",
    "text_features = X_test_text.shape[1]\n",
    "\n",
    "# Kiểm tra số đặc trưng\n",
    "print(f\"Tổng số đặc trưng trong mẫu: {num_features + text_features}\")  # Phải là 1684\n",
    "\n",
    "# Xây dựng danh sách tên đặc trưng cho SHAP\n",
    "feature_names = [f\"num_feat_{i}\" for i in range(num_features)]  # 126 cột số\n",
    "text_feature_names = [f\"text_feat_{i}\" for i in range(text_features)] \n",
    "full_feature_names = feature_names + text_feature_names  # Tổng 1684 tên\n",
    "\n",
    "# Chọn một mẫu duy nhất\n",
    "sample_num = X_test_num[12:13]  # Lấy mẫu duy nhất tại chỉ số 10\n",
    "sample_text = X_test_text[12:13]  # Lấy mẫu duy nhất tại chỉ số 10\n",
    "samples = np.concatenate([sample_num, sample_text], axis=1)\n",
    "\n",
    "# Xây dựng hàm dự đoán cho SHAP\n",
    "def predict_shap_wrapper(X):\n",
    "    \"\"\"\n",
    "    Chuyển đổi dữ liệu SHAP thành đầu vào phù hợp cho mô hình Transformer\n",
    "    \"\"\"\n",
    "    X_num = X[:, 0:num_features]\n",
    "    X_text = X[:, num_features:(num_features + text_features)]\n",
    "    return model.predict([X_num, X_text])\n",
    "\n",
    "# Dự đoán cho mẫu duy nhất\n",
    "prediction = predict_shap_wrapper(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7af95-5323-4818-923a-7a1892d73c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1af1e-32d7-4140-a5c2-2433620621a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn nền cho SHAP Explainer từ tập huấn luyện\n",
    "X_train_combined = np.concatenate([X_train_num, X_train_text], axis=1)\n",
    "background = shap.utils.sample(X_train_combined, 1)  # Lấy 1 mẫu ngẫu nhiên từ X_train_combined\n",
    "\n",
    "# Tạo SHAP Explainer\n",
    "try:\n",
    "    explainer = shap.DeepExplainer(model, background)  # Nếu là mô hình deep learning\n",
    "except:\n",
    "    explainer = shap.KernelExplainer(predict_shap_wrapper, background)  # Backup nếu lỗi\n",
    "\n",
    "# Đưa ra giải thích SHAP cho mẫu duy nhất\n",
    "shap_values = explainer.shap_values(samples)  # Giải thích cho mẫu duy nhất đã chọn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84548e-d349-43c7-9e83-4871688892e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính giá trị SHAP\n",
    "shap_values = explainer.shap_values(samples)\n",
    "\n",
    "# Xây dựng danh sách SHAP Explanation\n",
    "shap_explanations = [\n",
    "    shap.Explanation(\n",
    "        values=shap_values[i],  \n",
    "        base_values=explainer.expected_value,  \n",
    "        data=samples[i],  \n",
    "        feature_names=full_feature_names  \n",
    "    )\n",
    "    for i in range(len(samples))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40897a-bb09-4e38-ab25-0188d3f1165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo các mảng để lưu các đặc trưng phân loại theo lớp\n",
    "num_amp = []\n",
    "num_namp = []\n",
    "text_amp = []\n",
    "text_namp = []\n",
    "\n",
    "# Giả sử bạn đã có kết quả dự đoán\n",
    "prediction = predict_shap_wrapper(samples)  # Dự đoán cho mẫu (samples)\n",
    "prediction_class = \"amp\" if prediction[0] == 1 else \"namp\"  # Đặt giá trị lớp (giả sử 1 là 'amp' và 0 là 'namp')\n",
    "\n",
    "# Vẽ biểu đồ Waterfall Plot cho từng mẫu\n",
    "for i, shap_exp in enumerate(shap_explanations):\n",
    "    print(f\"Waterfall Plot cho mẫu {i+1}:\")\n",
    "    \n",
    "    # Chuyển ma trận (1684, 1) thành vector (1684,)\n",
    "    shap_exp.values = shap_exp.values.reshape(-1)\n",
    "    \n",
    "    # Tạo danh sách các giá trị tuyệt đối của SHAP values\n",
    "    abs_shap_values = np.abs(shap_exp.values)\n",
    "    \n",
    "    # Lấy các chỉ số của 9 đặc trưng quan trọng nhất (theo giá trị tuyệt đối của SHAP)\n",
    "    top_9_indices = np.argsort(abs_shap_values)[-9:]\n",
    "    \n",
    "    # Liệt kê tên của 9 đặc trưng quan trọng nhất\n",
    "    top_9_features = [shap_exp.feature_names[idx] for idx in top_9_indices]\n",
    "    \n",
    "    # In ra các tên đặc trưng quan trọng nhất\n",
    "    print(\"9 đặc trưng quan trọng nhất:\")\n",
    "    for feat in top_9_features:\n",
    "        print(feat)\n",
    "        \n",
    "        # Lấy số từ tên đặc trưng và phân loại theo lớp\n",
    "        if \"num_feat\" in feat:\n",
    "            num_id = int(feat.split(\"_\")[2])  # Lấy số từ num_feat_X\n",
    "            if prediction_class == \"amp\":\n",
    "                num_amp.append(num_id)\n",
    "            else:\n",
    "                num_namp.append(num_id)\n",
    "        elif \"text_feat\" in feat:\n",
    "            text_id = int(feat.split(\"_\")[2])  # Lấy số từ text_feat_X\n",
    "            if prediction_class == \"amp\":\n",
    "                text_amp.append(text_id)\n",
    "            else:\n",
    "                text_namp.append(text_id)\n",
    "    \n",
    "    # Vẽ biểu đồ Waterfall Plot\n",
    "    shap.plots.waterfall(shap_exp)\n",
    "\n",
    "# In ra kết quả phân loại các đặc trưng\n",
    "print(f\"num_amp: {num_amp}\")\n",
    "print(f\"num_namp: {num_namp}\")\n",
    "print(f\"text_amp: {text_amp}\")\n",
    "print(f\"text_namp: {text_namp}\")\n",
    "\n",
    "# Map từ chỉ số về từ thực tế trong tokenizer\n",
    "index2word = tokenizer.index_word\n",
    "\n",
    "# Map từ chỉ số về từ thực tế trong tokenizer (bỏ qua 0 và từ không tồn tại)\n",
    "amp_text_words = [index2word[idx] for idx in text_amp if idx != 0 and idx in index2word]\n",
    "namp_text_words = [index2word[idx] for idx in text_namp if idx != 0 and idx in index2word]\n",
    "\n",
    "# In kết quả\n",
    "print(\"Từ quan trọng trong lớp AMP (class 1):\", amp_text_words)\n",
    "print(\"Từ quan trọng trong lớp NAMP (class 0):\", namp_text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0de05-6349-44c0-8f62-98a40f3f18f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987b040-b961-4464-953c-690e7f071c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9966b06-5b46-43cc-b0e7-2fffbaa94e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26151a5-4526-43ec-bd96-93c2f18a7589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09e562-eab6-4d77-a2c9-d2640a38de8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
